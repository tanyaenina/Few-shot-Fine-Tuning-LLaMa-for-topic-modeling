# SummAI_NLP Challenge

The objective of this project is to fine-tune the LLaMA-2 model using a few-shot prompting strategy. 

## Technical Prerequisites

Given the computational constraints, I utilized Google Colab with a T4 GPU.

Below are the versions of libraries that I used:




## Challenges and Limitations

- Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., ... & Chen, W. (2021). Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685.
- 
